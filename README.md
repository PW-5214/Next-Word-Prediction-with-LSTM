# ğŸ§  Next Word Prediction with LSTM

### ğŸ”— Live App: [https://next-word-prediction-with-lstm-pnw.streamlit.app/](https://next-word-prediction-with-lstm-pnw.streamlit.app/)

This project demonstrates a **Next Word Prediction** system built using a **Long Short-Term Memory (LSTM)** neural network. The model is trained on text data to understand context and predict the most probable next word. A **Streamlit web app** is provided for real-time predictions.

---

## ğŸš€ Features

* âœ”ï¸ Tokenization of text data
* âœ”ï¸ Automatic sequence generation for training
* âœ”ï¸ LSTM-based deep learning model
* âœ”ï¸ Next-word prediction using temperature sampling
* âœ”ï¸ Streamlit interface for real-time prediction
* âœ”ï¸ Trained tokenizer + saved model for reusability

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ app.py                 # Streamlit web app
â”œâ”€â”€ model.h5               # Trained LSTM model
â”œâ”€â”€ tokenizer.pkl          # Saved Keras tokenizer
â”œâ”€â”€ dataset.txt            # Training corpus
â””â”€â”€ README.md              # Documentation
```

---

## ğŸ§© How It Works

### 1ï¸âƒ£ Data Preparation

* Raw text is cleaned and split into lines.
* Each line is converted to integer sequences using a tokenizer.
* Input sequences are generated like:

```
I love deep learning
â†’ ["I", "I love", "I love deep", "I love deep learning"]
```

### 2ï¸âƒ£ Training Data

```python
x , y = input_seq[:,:-1], input_seq[:,-1]
```

* `x` â†’ all words except last
* `y` â†’ last word (label for prediction)

### 3ï¸âƒ£ Model Architecture

```
Embedding â†’ LSTM â†’ Dense (Softmax)
```

### 4ï¸âƒ£ Prediction

* User enters a seed text
* Model predicts next word
* Word appended â†’ prediction continues

---

## ğŸ› ï¸ Installation & Setup

### 1ï¸âƒ£ Clone Repo

```
git clone https://github.com/yourusername/next-word-lstm.git
cd next-word-lstm
```

### 2ï¸âƒ£ Install Dependencies

```
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run Locally

```
streamlit run app.py
```

---

## ğŸŒ Live Hosted App

Click below to try the model:

ğŸ‘‰ **[https://next-word-prediction-with-lstm-pnw.streamlit.app/](https://next-word-prediction-with-lstm-pnw.streamlit.app/)**

---

## ğŸ“Š Model Summary

* **Embedding Dimension**: 100
* **LSTM Units**: 150
* **Optimizer**: Adam
* **Loss Function**: Categorical Crossentropy
* **Accuracy Achieved**: ~90% (depends on dataset)

---

## ğŸ“¦ Requirements

```
tensorflow
streamlit
numpy
pickle
keras
```

---

## ğŸ¤ Contribution

Pull requests are welcome! Improve UI, model accuracy, or add NLP features such as:

* Beam search
* Bi-LSTM
* GRU model
* Transformer-based next-word prediction


## â¤ï¸ Author

**Prathmesh Wavhal**
Feel free to connect or ask queries!
